{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### **CUDA**\n","Below is an example that runs native CUDA code.\n","\n","1.   We investigate the CUDA version, drivers and the avaiable GPU with nvidia-smi and nvcc-version\n","2.   We use the IPython magic command \"%%writefile filename\" to save a *.cu program\n","3.   We then compile and run the *.cu program with nvcc\n","\n","\n","\n","\n","\n"],"metadata":{"id":"q0-ZomlNSrF5"}},{"cell_type":"code","source":["!nvcc --version\n","!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yJlrROAn5Rqj","outputId":"4b463339-b39d-43b9-adf5-01830388a3cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2021 NVIDIA Corporation\n","Built on Sun_Feb_14_21:12:58_PST_2021\n","Cuda compilation tools, release 11.2, V11.2.152\n","Build cuda_11.2.r11.2/compiler.29618528_0\n","Thu Oct 27 15:43:18 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   51C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":["\n","## Next, we write a naive CUDA code and save it as 'vectorAdd_naive.cu'\n"],"metadata":{"id":"vsbr4brQH6v3"}},{"cell_type":"code","source":["%%writefile vectorAdd_naive.cu\n","#include <stdio.h>\n","#include <stdlib.h>\n","\n","__global__ void add(int *a, int *b, int *c) {\n","  *c = *a + *b;\n","}\n","\n","int main() {\n","\n","  // host copies of variables a, b & c\n","  int a, b, c;\n","\n","  // device copies of variables a, b & c\n","  int *d_a, *d_b, *d_c;\n","\n","  // Allocate space for device copies of a, b, c\n","  int size = sizeof(int);\n","  cudaMalloc((void **)&d_a, size);\n","  cudaMalloc((void **)&d_b, size);\n","  cudaMalloc((void **)&d_c, size);\n","\n","  // Setup input values\n","  c = 0;\n","  a = 3;\n","  b = 5;\n","\n","  // Copy input data from host to device\n","  cudaMemcpy(d_a, &a, size, cudaMemcpyHostToDevice);\n","  cudaMemcpy(d_b, &b, size, cudaMemcpyHostToDevice);\n","\n","  // Launch add() kernel on GPU\n","  add<<<1,1>>>(d_a, d_b, d_c);\n","\n","  // Copy result from device back to host\n","  cudaError err = cudaMemcpy(&c, d_c, size, cudaMemcpyDeviceToHost);\n","  if(err!=cudaSuccess) {\n","      printf(\"CUDA error copying to Host: %s\\n\", cudaGetErrorString(err));\n","  }\n","\n","  printf(\"result is %d\\n\",c);\n","\n","  // Cleanup\n","  cudaFree(d_a);\n","  cudaFree(d_b);\n","  cudaFree(d_c);\n","  return 0;\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T0S5AUrl4eI8","outputId":"de57794f-f50d-40b7-a1cc-e691e5e4a2af","executionInfo":{"status":"ok","timestamp":1691599551968,"user_tz":-120,"elapsed":340,"user":{"displayName":"ScaLab Group","userId":"05321465319343100426"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting vectorAdd_naive.cu\n"]}]},{"cell_type":"markdown","source":["## We compile the saved cuda code using nvcc compiler"],"metadata":{"id":"TqdaBa9wIICn"}},{"cell_type":"code","source":["!nvcc vectorAdd_naive.cu -o vectorAdd_naive\n","!ls\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TvYps9NQ40NC","outputId":"ab100a1e-af83-4006-a226-f389b677113d","executionInfo":{"status":"ok","timestamp":1691599568949,"user_tz":-120,"elapsed":2211,"user":{"displayName":"ScaLab Group","userId":"05321465319343100426"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sample_data  vectorAdd_naive  vectorAdd_naive.cu\n"]}]},{"cell_type":"markdown","source":["## Finally, we execute the binary of the compiled code"],"metadata":{"id":"SUALHJy9IPvG"}},{"cell_type":"code","source":["!./vectorAdd_naive"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gF-iISqy7O2E","outputId":"464beaf3-5499-4804-d090-a8d891efab3e","executionInfo":{"status":"ok","timestamp":1691599579791,"user_tz":-120,"elapsed":590,"user":{"displayName":"ScaLab Group","userId":"05321465319343100426"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["result is 8\n"]}]},{"cell_type":"markdown","source":["\n","## Next, we write a more complete version of vectorAdd CUDA code and save it as 'vectorAdd_v2.cu'\n"],"metadata":{"id":"Zz1DgGBvL-GB"}},{"cell_type":"code","source":["%%writefile vectorAdd_v2.cu\n","#include <stdio.h>\n","#include <sys/time.h>\n","\n","#define DataType double\n","\n","__global__ void vecAdd(DataType *in1, DataType *in2, DataType *out, int len) {\n","  //@@ Insert code to implement vector addition here\n","  int index = threadIdx.x + blockIdx.x * blockDim.x;\n","  if (index < len) {\n","    out[index] = in1[index] + in2[index];\n","  }\n","}\n","\n","//@@ Insert code to implement timer\n","struct timeval t_start, t_end;\n","void myCPUTimer_start(){\n","  gettimeofday(&t_start, 0);\n","}\n","//@@ Insert code to implement timer\n","void myCPUTimer_stop(){\n","  cudaDeviceSynchronize();\n","  gettimeofday(&t_end, 0);\n","  double time = (1000000.0*(t_end.tv_sec-t_start.tv_sec) + t_end.tv_usec-t_start.tv_usec);\n","  printf(\"Elasped %6.1f microseconds \\n\", time);\n","}\n","\n","int main(int argc, char **argv) {\n","\n","  int inputLength;\n","  DataType *hostInput1;\n","  DataType *hostInput2;\n","  DataType *hostOutput;\n","  DataType *resultRef;\n","  DataType *deviceInput1;\n","  DataType *deviceInput2;\n","  DataType *deviceOutput;\n","\n","\n","  //@@ Insert code below to read in inputLength from args\n","  inputLength = atoi(argv[1]);\n","  printf(\"The input length is %d\\n\", inputLength);\n","\n","  //@@ Insert code below to allocate Host memory for input and output\n","  hostInput1 = (DataType *)malloc(inputLength * sizeof(DataType));\n","  hostInput2 = (DataType *)malloc(inputLength * sizeof(DataType));\n","  hostOutput = (DataType *)malloc(inputLength * sizeof(DataType));\n","  resultRef  = (DataType *)malloc(inputLength * sizeof(DataType));\n","\n","  //@@ Insert code below to initialize hostInput1 and hostInput2 to random numbers, and create reference result in CPU\n","  for(int i=0; i<inputLength; i++){\n","    hostInput1[i] = 1.0;\n","    hostInput2[i] = 2.0;\n","    resultRef[i]  = hostInput1[i] + hostInput2[i];\n","  }\n","\n","  //@@ Insert code below to allocate GPU memory here\n","  cudaMalloc((void **)&deviceInput1, inputLength * sizeof(DataType));\n","  cudaMalloc((void **)&deviceInput2, inputLength * sizeof(DataType));\n","  cudaMalloc((void **)&deviceOutput, inputLength * sizeof(DataType));\n","\n","  //@@ Insert code to below to Copy memory to the GPU here\n","  cudaMemcpy(deviceInput1, hostInput1, inputLength * sizeof(DataType), cudaMemcpyHostToDevice);\n","  cudaMemcpy(deviceInput2, hostInput2, inputLength * sizeof(DataType), cudaMemcpyHostToDevice);\n","\n","  //@@ Initialize the 1D grid and block dimensions here\n","  dim3 blockDim(32);\n","  dim3 gridDim(ceil(((float)inputLength) / ((float)blockDim.x)));\n","\n","  //@@ Launch the GPU Kernel here\n","  vecAdd<<<gridDim, blockDim>>>(deviceInput1, deviceInput2, deviceOutput,\n","                                inputLength);\n","\n","\n","  //@@ Copy the GPU memory back to the CPU here\n","  cudaMemcpy(hostOutput, deviceOutput, inputLength * sizeof(DataType), cudaMemcpyDeviceToHost);\n","\n","\n","  //@@ Insert code below to compare the output with the reference\n","  bool valid = true;\n","  for(int i=0; i<inputLength; i++){\n","    if( hostOutput[i] != resultRef[i] ){\n","      printf(\"hostOutput[%d] = %f != %f\\n\", i, hostOutput[i], resultRef[i]);\n","      valid = false;\n","    }\n","  }\n","  if(valid) printf(\"valid\\n\");\n","\n","  //@@ Free the GPU memory here\n","  cudaFree(deviceInput1);\n","  cudaFree(deviceInput2);\n","  cudaFree(deviceOutput);\n","\n","  //@@ Free the CPU memory here\n","  free(hostInput1);\n","  free(hostInput2);\n","  free(hostOutput);\n","  free(resultRef);\n","\n","  return 0;\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qjr33BOi65cf","executionInfo":{"status":"ok","timestamp":1691599585761,"user_tz":-120,"elapsed":322,"user":{"displayName":"ScaLab Group","userId":"05321465319343100426"}},"outputId":"0d5482ce-7aed-4064-fca5-770d30c9a212"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing vectorAdd_v2.cu\n"]}]},{"cell_type":"code","source":["!nvcc -o vectorAdd vectorAdd_v2.cu"],"metadata":{"id":"G4tBI5kbMYwL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!./vectorAdd 131070"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j9QkT1m-Mhng","executionInfo":{"status":"ok","timestamp":1691599656263,"user_tz":-120,"elapsed":538,"user":{"displayName":"ScaLab Group","userId":"05321465319343100426"}},"outputId":"273ee752-78db-4d4e-b9f4-7ec57f65d7e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The input length is 131070\n","valid\n"]}]},{"cell_type":"markdown","source":["# Next, we use NVPROF to profile the program and geting basic timing of activities on GPU"],"metadata":{"id":"TECIcI2TMpCi"}},{"cell_type":"code","source":["!nvprof ./vectorAdd 131070"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wXEFYaIo5KKU","executionInfo":{"status":"ok","timestamp":1691599633777,"user_tz":-120,"elapsed":927,"user":{"displayName":"ScaLab Group","userId":"05321465319343100426"}},"outputId":"e99b432f-4b42-49fb-d3a4-67818ac2164a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The input length is 131070\n","==3374== NVPROF is profiling process 3374, command: ./vectorAdd 131070\n","valid\n","==3374== Profiling application: ./vectorAdd 131070\n","==3374== Profiling result:\n","            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n"," GPU activities:   59.70%  175.55us         2  87.774us  87.486us  88.062us  [CUDA memcpy HtoD]\n","                   34.12%  100.32us         1  100.32us  100.32us  100.32us  [CUDA memcpy DtoH]\n","                    6.18%  18.176us         1  18.176us  18.176us  18.176us  vecAdd(double*, double*, double*, int)\n","      API calls:   98.77%  243.64ms         3  81.212ms  6.3460us  243.55ms  cudaMalloc\n","                    0.61%  1.5094ms         3  503.14us  247.05us  851.02us  cudaMemcpy\n","                    0.43%  1.0728ms         1  1.0728ms  1.0728ms  1.0728ms  cuDeviceGetPCIBusId\n","                    0.10%  257.65us         3  85.883us  24.121us  119.73us  cudaFree\n","                    0.05%  134.95us       101  1.3360us     133ns  55.040us  cuDeviceGetAttribute\n","                    0.01%  30.539us         1  30.539us  30.539us  30.539us  cudaLaunchKernel\n","                    0.01%  26.831us         1  26.831us  26.831us  26.831us  cuDeviceGetName\n","                    0.00%  1.5790us         3     526ns     192ns  1.0900us  cuDeviceGetCount\n","                    0.00%     935ns         2     467ns     275ns     660ns  cuDeviceGet\n","                    0.00%     586ns         1     586ns     586ns     586ns  cuModuleGetLoadingMode\n","                    0.00%     374ns         1     374ns     374ns     374ns  cuDeviceGetUuid\n","                    0.00%     371ns         1     371ns     371ns     371ns  cuDeviceTotalMem\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"yM4hy17q92Bd"}}]}